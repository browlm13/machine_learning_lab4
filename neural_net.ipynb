{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n",
      "-0.5 0.5\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# lets load up the handwritten digit dataset\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "ds = load_digits()\n",
    "X = ds.data/16.0-0.5\n",
    "y = ds.target\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(np.min(X),np.max(X))\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True,)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = X[y == i][0].reshape(8, 8)\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=5, sharex=True, sharey=True,)\n",
    "ax = ax.flatten()\n",
    "digit = 4\n",
    "x_digits = X[y == digit]\n",
    "for i in range(25):\n",
    "    img = x_digits[i].reshape(8, 8)\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64)\n",
      "(1437,)\n",
      "(360, 64)\n",
      "(360,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example adapted from https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "# Original Author: Sebastian Raschka\n",
    "\n",
    "# This is the optional book we use in the course, excellent intuitions and straightforward programming examples\n",
    "# please note, however, that this code has been manipulated to reflect our assumptions and notation.\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# start with a simple base classifier, which can't be fit or predicted\n",
    "# it only has internal classes to be used by classes that will subclass it\n",
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=30, C=0.0, epochs=500, eta=0.001, phi=\"sigmoid\", objective_function=\"quadratic\", random_state=None):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.phi = phi\n",
    "        self.objective_function = objective_function\n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        W1_num_elems = (self.n_features_ + 1)*self.n_hidden\n",
    "        W1 = np.random.uniform(-1.0, 1.0, size=W1_num_elems)\n",
    "        W1 = W1.reshape(self.n_hidden, self.n_features_ + 1) # reshape to be W\n",
    "        \n",
    "        W2_num_elems = (self.n_hidden + 1)*self.n_output_\n",
    "        W2 = np.random.uniform(-1.0, 1.0, size=W2_num_elems)\n",
    "        W2 = W2.reshape(self.n_output_, self.n_hidden + 1)\n",
    "        return W1, W2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
    "        # 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _linear(z):\n",
    "        return z\n",
    "    \n",
    "    def _phi(self, z):\n",
    "        if self.phi == \"sigmoid\":\n",
    "            return self._sigmoid(z)\n",
    "        if self.phi == \"linear\":\n",
    "            return self._linear(z)\n",
    "        \n",
    "    def _phi_grad(self, a):\n",
    "        if self.phi == \"sigmoid\":\n",
    "            return a*(1-a)\n",
    "        if self.phi == \"linear\":\n",
    "            return a\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        # only compute for non-bias terms\n",
    "        return (lambda_/2.0) * np.sqrt(np.mean(W1[:, 1:] ** 2) + np.mean(W2[:, 1:] ** 2))\n",
    "    \n",
    "    def _objective_grad(self, y, y_hat):\n",
    "        obj_grad = -2*(y - y_hat) * self._phi_grad(y_hat)\n",
    "        return obj_grad\n",
    "    \n",
    "    @staticmethod\n",
    "    def _MSE(Y_enc, Y_hat):\n",
    "        cost = np.mean((Y_enc-Y_hat)**2)\n",
    "        return cost\n",
    "    \n",
    "    @staticmethod\n",
    "    def _log_likelihood(Y_enc, Y_hat):\n",
    "        term1 = -Y_enc * (np.log(Y_hat))\n",
    "        term2 = (1.0 - Y_enc) * np.log(1.0 - Y_hat)\n",
    "        cost = np.sum(term1 - term2)\n",
    "        return cost\n",
    "        \n",
    "    def _cost(self,Y_hat,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        if self.objective_function == \"quadratic\":\n",
    "            cost = self._MSE(Y_enc, Y_hat)\n",
    "        if self.objective_function == \"cross_entropy\":\n",
    "            cost = self._log_likelihood(Y_enc, Y_hat)\n",
    "        #cost = np.mean((Y_enc-A3)**2)\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerPerceptron(TwoLayerPerceptronBase):\n",
    "    def _feedforward(self, X, W1, W2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        -----------\n",
    "        X : Input layer with original features.\n",
    "        W1: Weight matrix for input layer -> hidden layer.\n",
    "        W2: Weight matrix for hidden layer -> output layer.\n",
    "        ----------\n",
    "        a1-a3 : activations into layer (or output layer)\n",
    "        z1-z2 : layer inputs \n",
    "\n",
    "        \"\"\"\n",
    "        A1 = self._add_bias_unit(X.T, how='row')\n",
    "        Z1 = W1 @ A1\n",
    "        A2 = self._phi(Z1)\n",
    "        A2 = self._add_bias_unit(A2, how='row')\n",
    "        Z2 = W2 @ A2\n",
    "        A3 = self._phi(Z2)\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # backpropagation\n",
    "        grad1 = np.zeros(W1.shape)\n",
    "        grad2 = np.zeros(W2.shape)\n",
    "        \n",
    "        # for each instance's activations \n",
    "        for (a1,a2,a3,y) in zip(A1.T,A2.T,A3.T,Y_enc.T):\n",
    "            \n",
    "            dJ_dz2 = self._objective_grad(y, a3)\n",
    "            dJ_dz1 = dJ_dz2 @ W2 @ np.diag(self._phi_grad(a2))\n",
    "                         \n",
    "            dz2_dw2 = a2[np.newaxis,:]\n",
    "            dz1_dw1 = a1[np.newaxis,:]\n",
    "            \n",
    "            # grad = VA.T \n",
    "            grad2 += dJ_dz2[:,np.newaxis]  @ dz2_dw2\n",
    "            grad1 += dJ_dz1[1:,np.newaxis] @ dz1_dw1\n",
    "            # don't incorporate bias term in the z1 gradient \n",
    "            # (its added in a2 from another layer)\n",
    "            \n",
    "\n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += (W1[:, 1:] * self.l2_C)\n",
    "        grad2[:, 1:] += (W2[:, 1:] * self.l2_C)\n",
    "\n",
    "        return grad1, grad2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        _, _, _, _, A3 = self._feedforward(X, self.W1, self.W2)\n",
    "        y_pred = np.argmax(A3, axis=0)\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        \"\"\" Learn weights from training data.\"\"\"\n",
    "        \n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        self.cost_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            # feedforward all instances\n",
    "            A1, Z1, A2, Z2, A3 = self._feedforward(X_data,self.W1,self.W2)\n",
    "            \n",
    "            cost = self._cost(A3,Y_enc,self.W1,self.W2)\n",
    "            self.cost_.append(cost)\n",
    "\n",
    "            # compute gradient via backpropagation\n",
    "            grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, Y_enc=Y_enc,\n",
    "                                              W1=self.W1, W2=self.W2)\n",
    "\n",
    "            self.W1 -= self.eta * grad1\n",
    "            self.W2 -= self.eta * grad2\n",
    "            \n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(n_hidden=50, \n",
    "              C=0.1, # tradeoff L2 regularizer\n",
    "              epochs=200, # iterations\n",
    "              eta=0.001,  # learning rate\n",
    "              random_state=1,\n",
    "              phi=\"sigmoid\",\n",
    "              objective_function=\"quadratic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 200/200"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.9305555555555556\n",
      "CPU times: user 29.4 s, sys: 3.58 s, total: 33 s\n",
      "Wall time: 8.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "nn = TwoLayerPerceptron(**params)\n",
    "nn.fit(X_train, y_train, print_progress=10)\n",
    "yhat = nn.predict(X_test)\n",
    "print('Test acc:',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
